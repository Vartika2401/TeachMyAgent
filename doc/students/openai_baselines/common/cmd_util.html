<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>TeachMyAgent.students.openai_baselines.common.cmd_util API documentation</title>
<meta name="description" content="Helpers for scripts like run_atari.py." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/favicon-96x96.png?raw=true" />
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TeachMyAgent.students.openai_baselines.common.cmd_util</code></h1>
</header>
<section id="section-intro">
<p>Helpers for scripts like run_atari.py.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Helpers for scripts like run_atari.py.
&#34;&#34;&#34;

import os
try:
    from mpi4py import MPI
except ImportError:
    MPI = None

import gym
from gym.wrappers import FlattenObservation, FilterObservation
from TeachMyAgent.students.openai_baselines import logger
from TeachMyAgent.students.openai_baselines.bench import Monitor
from TeachMyAgent.students.openai_baselines.common import set_global_seeds
from TeachMyAgent.students.openai_baselines.common.atari_wrappers import make_atari, wrap_deepmind
from TeachMyAgent.students.openai_baselines.common.vec_env.subproc_vec_env import SubprocVecEnv
from TeachMyAgent.students.openai_baselines.common.vec_env.dummy_vec_env import DummyVecEnv
from TeachMyAgent.students.openai_baselines.common import retro_wrappers
from TeachMyAgent.students.openai_baselines.common.wrappers import ClipActionsWrapper

def make_vec_env(env_id, env_type, num_env, seed,
                 wrapper_kwargs=None,
                 env_kwargs=None,
                 start_index=0,
                 reward_scale=1.0,
                 flatten_dict_observations=True,
                 gamestate=None,
                 initializer=None,
                 force_dummy=False):
    &#34;&#34;&#34;
    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.
    &#34;&#34;&#34;
    wrapper_kwargs = wrapper_kwargs or {}
    env_kwargs = env_kwargs or {}
    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0
    seed = seed + 10000 * mpi_rank if seed is not None else None
    logger_dir = logger.get_dir()
    def make_thunk(rank, initializer=None):
        return lambda: make_env(
            env_id=env_id,
            env_type=env_type,
            mpi_rank=mpi_rank,
            subrank=rank,
            seed=seed,
            reward_scale=reward_scale,
            gamestate=gamestate,
            flatten_dict_observations=flatten_dict_observations,
            wrapper_kwargs=wrapper_kwargs,
            env_kwargs=env_kwargs,
            logger_dir=logger_dir,
            initializer=initializer
        )

    set_global_seeds(seed)
    if not force_dummy and num_env &gt; 1:
        return SubprocVecEnv([make_thunk(i + start_index, initializer=initializer) for i in range(num_env)])
    else:
        return DummyVecEnv([make_thunk(i + start_index, initializer=None) for i in range(num_env)])


def make_env(env_id, env_type, mpi_rank=0, subrank=0, seed=None, reward_scale=1.0, gamestate=None, flatten_dict_observations=True, wrapper_kwargs=None, env_kwargs=None, logger_dir=None, initializer=None):
    if initializer is not None:
        initializer(mpi_rank=mpi_rank, subrank=subrank)

    wrapper_kwargs = wrapper_kwargs or {}
    env_kwargs = env_kwargs or {}
    if &#39;:&#39; in env_id:
        import re
        import importlib
        module_name = re.sub(&#39;:.*&#39;,&#39;&#39;,env_id)
        env_id = re.sub(&#39;.*:&#39;, &#39;&#39;, env_id)
        importlib.import_module(module_name)
    if env_type == &#39;atari&#39;:
        env = make_atari(env_id)
    elif env_type == &#39;retro&#39;:
        import retro
        gamestate = gamestate or retro.State.DEFAULT
        env = retro_wrappers.make_retro(game=env_id, max_episode_steps=10000, use_restricted_actions=retro.Actions.DISCRETE, state=gamestate)
    else:
        env = gym.make(env_id, **env_kwargs)

    if flatten_dict_observations and isinstance(env.observation_space, gym.spaces.Dict):
        env = FlattenObservation(env)

    env.seed(seed + subrank if seed is not None else None)
    env = Monitor(env,
                  logger_dir and os.path.join(logger_dir, str(mpi_rank) + &#39;.&#39; + str(subrank)),
                  allow_early_resets=True)


    if env_type == &#39;atari&#39;:
        env = wrap_deepmind(env, **wrapper_kwargs)
    elif env_type == &#39;retro&#39;:
        if &#39;frame_stack&#39; not in wrapper_kwargs:
            wrapper_kwargs[&#39;frame_stack&#39;] = 1
        env = retro_wrappers.wrap_deepmind_retro(env, **wrapper_kwargs)

    if isinstance(env.action_space, gym.spaces.Box):
        env = ClipActionsWrapper(env)

    if reward_scale != 1:
        env = retro_wrappers.RewardScaler(env, reward_scale)

    return env


def make_mujoco_env(env_id, seed, reward_scale=1.0):
    &#34;&#34;&#34;
    Create a wrapped, monitored gym.Env for MuJoCo.
    &#34;&#34;&#34;
    rank = MPI.COMM_WORLD.Get_rank()
    myseed = seed  + 1000 * rank if seed is not None else None
    set_global_seeds(myseed)
    env = gym.make(env_id)
    logger_path = None if logger.get_dir() is None else os.path.join(logger.get_dir(), str(rank))
    env = Monitor(env, logger_path, allow_early_resets=True)
    env.seed(seed)
    if reward_scale != 1.0:
        from TeachMyAgent.students.openai_baselines.common.retro_wrappers import RewardScaler
        env = RewardScaler(env, reward_scale)
    return env

def make_robotics_env(env_id, seed, rank=0):
    &#34;&#34;&#34;
    Create a wrapped, monitored gym.Env for MuJoCo.
    &#34;&#34;&#34;
    set_global_seeds(seed)
    env = gym.make(env_id)
    env = FlattenObservation(FilterObservation(env, [&#39;observation&#39;, &#39;desired_goal&#39;]))
    env = Monitor(
        env, logger.get_dir() and os.path.join(logger.get_dir(), str(rank)),
        info_keywords=(&#39;is_success&#39;,))
    env.seed(seed)
    return env

def arg_parser():
    &#34;&#34;&#34;
    Create an empty argparse.ArgumentParser.
    &#34;&#34;&#34;
    import argparse
    return argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)

def atari_arg_parser():
    &#34;&#34;&#34;
    Create an argparse.ArgumentParser for run_atari.py.
    &#34;&#34;&#34;
    print(&#39;Obsolete - use common_arg_parser instead&#39;)
    return common_arg_parser()

def mujoco_arg_parser():
    print(&#39;Obsolete - use common_arg_parser instead&#39;)
    return common_arg_parser()

def common_arg_parser():
    &#34;&#34;&#34;
    Create an argparse.ArgumentParser for run_mujoco.py.
    &#34;&#34;&#34;
    parser = arg_parser()
    parser.add_argument(&#39;--env&#39;, help=&#39;environment ID&#39;, type=str, default=&#39;Reacher-v2&#39;)
    parser.add_argument(&#39;--env_type&#39;, help=&#39;type of environment, used when the environment type cannot be automatically determined&#39;, type=str)
    parser.add_argument(&#39;--seed&#39;, help=&#39;RNG seed&#39;, type=int, default=None)
    parser.add_argument(&#39;--alg&#39;, help=&#39;Algorithm&#39;, type=str, default=&#39;ppo2&#39;)
    parser.add_argument(&#39;--num_timesteps&#39;, type=float, default=1e6),
    parser.add_argument(&#39;--network&#39;, help=&#39;network type (mlp, cnn, lstm, cnn_lstm, conv_only)&#39;, default=None)
    parser.add_argument(&#39;--gamestate&#39;, help=&#39;game state to load (so far only used in retro games)&#39;, default=None)
    parser.add_argument(&#39;--num_env&#39;, help=&#39;Number of environment copies being run in parallel. When not specified, set to number of cpus for Atari, and to 1 for Mujoco&#39;, default=None, type=int)
    parser.add_argument(&#39;--reward_scale&#39;, help=&#39;Reward scale factor. Default: 1.0&#39;, default=1.0, type=float)
    parser.add_argument(&#39;--save_path&#39;, help=&#39;Path to save trained model to&#39;, default=None, type=str)
    parser.add_argument(&#39;--save_video_interval&#39;, help=&#39;Save video every x steps (0 = disabled)&#39;, default=0, type=int)
    parser.add_argument(&#39;--save_video_length&#39;, help=&#39;Length of recorded video. Default: 200&#39;, default=200, type=int)
    parser.add_argument(&#39;--log_path&#39;, help=&#39;Directory to save learning curve data.&#39;, default=None, type=str)
    parser.add_argument(&#39;--play&#39;, default=False, action=&#39;store_true&#39;)
    return parser

def robotics_arg_parser():
    &#34;&#34;&#34;
    Create an argparse.ArgumentParser for run_mujoco.py.
    &#34;&#34;&#34;
    parser = arg_parser()
    parser.add_argument(&#39;--env&#39;, help=&#39;environment ID&#39;, type=str, default=&#39;FetchReach-v0&#39;)
    parser.add_argument(&#39;--seed&#39;, help=&#39;RNG seed&#39;, type=int, default=None)
    parser.add_argument(&#39;--num-timesteps&#39;, type=int, default=int(1e6))
    return parser


def parse_unknown_args(args):
    &#34;&#34;&#34;
    Parse arguments not consumed by arg parser into a dictionary
    &#34;&#34;&#34;
    retval = {}
    preceded_by_key = False
    for arg in args:
        if arg.startswith(&#39;--&#39;):
            if &#39;=&#39; in arg:
                key = arg.split(&#39;=&#39;)[0][2:]
                value = arg.split(&#39;=&#39;)[1]
                retval[key] = value
            else:
                key = arg[2:]
                preceded_by_key = True
        elif preceded_by_key:
            retval[key] = arg
            preceded_by_key = False

    return retval</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.arg_parser"><code class="name flex">
<span>def <span class="ident">arg_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Create an empty argparse.ArgumentParser.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def arg_parser():
    &#34;&#34;&#34;
    Create an empty argparse.ArgumentParser.
    &#34;&#34;&#34;
    import argparse
    return argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.atari_arg_parser"><code class="name flex">
<span>def <span class="ident">atari_arg_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Create an argparse.ArgumentParser for run_atari.py.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def atari_arg_parser():
    &#34;&#34;&#34;
    Create an argparse.ArgumentParser for run_atari.py.
    &#34;&#34;&#34;
    print(&#39;Obsolete - use common_arg_parser instead&#39;)
    return common_arg_parser()</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.common_arg_parser"><code class="name flex">
<span>def <span class="ident">common_arg_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Create an argparse.ArgumentParser for run_mujoco.py.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def common_arg_parser():
    &#34;&#34;&#34;
    Create an argparse.ArgumentParser for run_mujoco.py.
    &#34;&#34;&#34;
    parser = arg_parser()
    parser.add_argument(&#39;--env&#39;, help=&#39;environment ID&#39;, type=str, default=&#39;Reacher-v2&#39;)
    parser.add_argument(&#39;--env_type&#39;, help=&#39;type of environment, used when the environment type cannot be automatically determined&#39;, type=str)
    parser.add_argument(&#39;--seed&#39;, help=&#39;RNG seed&#39;, type=int, default=None)
    parser.add_argument(&#39;--alg&#39;, help=&#39;Algorithm&#39;, type=str, default=&#39;ppo2&#39;)
    parser.add_argument(&#39;--num_timesteps&#39;, type=float, default=1e6),
    parser.add_argument(&#39;--network&#39;, help=&#39;network type (mlp, cnn, lstm, cnn_lstm, conv_only)&#39;, default=None)
    parser.add_argument(&#39;--gamestate&#39;, help=&#39;game state to load (so far only used in retro games)&#39;, default=None)
    parser.add_argument(&#39;--num_env&#39;, help=&#39;Number of environment copies being run in parallel. When not specified, set to number of cpus for Atari, and to 1 for Mujoco&#39;, default=None, type=int)
    parser.add_argument(&#39;--reward_scale&#39;, help=&#39;Reward scale factor. Default: 1.0&#39;, default=1.0, type=float)
    parser.add_argument(&#39;--save_path&#39;, help=&#39;Path to save trained model to&#39;, default=None, type=str)
    parser.add_argument(&#39;--save_video_interval&#39;, help=&#39;Save video every x steps (0 = disabled)&#39;, default=0, type=int)
    parser.add_argument(&#39;--save_video_length&#39;, help=&#39;Length of recorded video. Default: 200&#39;, default=200, type=int)
    parser.add_argument(&#39;--log_path&#39;, help=&#39;Directory to save learning curve data.&#39;, default=None, type=str)
    parser.add_argument(&#39;--play&#39;, default=False, action=&#39;store_true&#39;)
    return parser</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.make_env"><code class="name flex">
<span>def <span class="ident">make_env</span></span>(<span>env_id, env_type, mpi_rank=0, subrank=0, seed=None, reward_scale=1.0, gamestate=None, flatten_dict_observations=True, wrapper_kwargs=None, env_kwargs=None, logger_dir=None, initializer=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_env(env_id, env_type, mpi_rank=0, subrank=0, seed=None, reward_scale=1.0, gamestate=None, flatten_dict_observations=True, wrapper_kwargs=None, env_kwargs=None, logger_dir=None, initializer=None):
    if initializer is not None:
        initializer(mpi_rank=mpi_rank, subrank=subrank)

    wrapper_kwargs = wrapper_kwargs or {}
    env_kwargs = env_kwargs or {}
    if &#39;:&#39; in env_id:
        import re
        import importlib
        module_name = re.sub(&#39;:.*&#39;,&#39;&#39;,env_id)
        env_id = re.sub(&#39;.*:&#39;, &#39;&#39;, env_id)
        importlib.import_module(module_name)
    if env_type == &#39;atari&#39;:
        env = make_atari(env_id)
    elif env_type == &#39;retro&#39;:
        import retro
        gamestate = gamestate or retro.State.DEFAULT
        env = retro_wrappers.make_retro(game=env_id, max_episode_steps=10000, use_restricted_actions=retro.Actions.DISCRETE, state=gamestate)
    else:
        env = gym.make(env_id, **env_kwargs)

    if flatten_dict_observations and isinstance(env.observation_space, gym.spaces.Dict):
        env = FlattenObservation(env)

    env.seed(seed + subrank if seed is not None else None)
    env = Monitor(env,
                  logger_dir and os.path.join(logger_dir, str(mpi_rank) + &#39;.&#39; + str(subrank)),
                  allow_early_resets=True)


    if env_type == &#39;atari&#39;:
        env = wrap_deepmind(env, **wrapper_kwargs)
    elif env_type == &#39;retro&#39;:
        if &#39;frame_stack&#39; not in wrapper_kwargs:
            wrapper_kwargs[&#39;frame_stack&#39;] = 1
        env = retro_wrappers.wrap_deepmind_retro(env, **wrapper_kwargs)

    if isinstance(env.action_space, gym.spaces.Box):
        env = ClipActionsWrapper(env)

    if reward_scale != 1:
        env = retro_wrappers.RewardScaler(env, reward_scale)

    return env</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.make_mujoco_env"><code class="name flex">
<span>def <span class="ident">make_mujoco_env</span></span>(<span>env_id, seed, reward_scale=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a wrapped, monitored gym.Env for MuJoCo.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_mujoco_env(env_id, seed, reward_scale=1.0):
    &#34;&#34;&#34;
    Create a wrapped, monitored gym.Env for MuJoCo.
    &#34;&#34;&#34;
    rank = MPI.COMM_WORLD.Get_rank()
    myseed = seed  + 1000 * rank if seed is not None else None
    set_global_seeds(myseed)
    env = gym.make(env_id)
    logger_path = None if logger.get_dir() is None else os.path.join(logger.get_dir(), str(rank))
    env = Monitor(env, logger_path, allow_early_resets=True)
    env.seed(seed)
    if reward_scale != 1.0:
        from TeachMyAgent.students.openai_baselines.common.retro_wrappers import RewardScaler
        env = RewardScaler(env, reward_scale)
    return env</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.make_robotics_env"><code class="name flex">
<span>def <span class="ident">make_robotics_env</span></span>(<span>env_id, seed, rank=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a wrapped, monitored gym.Env for MuJoCo.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_robotics_env(env_id, seed, rank=0):
    &#34;&#34;&#34;
    Create a wrapped, monitored gym.Env for MuJoCo.
    &#34;&#34;&#34;
    set_global_seeds(seed)
    env = gym.make(env_id)
    env = FlattenObservation(FilterObservation(env, [&#39;observation&#39;, &#39;desired_goal&#39;]))
    env = Monitor(
        env, logger.get_dir() and os.path.join(logger.get_dir(), str(rank)),
        info_keywords=(&#39;is_success&#39;,))
    env.seed(seed)
    return env</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.make_vec_env"><code class="name flex">
<span>def <span class="ident">make_vec_env</span></span>(<span>env_id, env_type, num_env, seed, wrapper_kwargs=None, env_kwargs=None, start_index=0, reward_scale=1.0, flatten_dict_observations=True, gamestate=None, initializer=None, force_dummy=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_vec_env(env_id, env_type, num_env, seed,
                 wrapper_kwargs=None,
                 env_kwargs=None,
                 start_index=0,
                 reward_scale=1.0,
                 flatten_dict_observations=True,
                 gamestate=None,
                 initializer=None,
                 force_dummy=False):
    &#34;&#34;&#34;
    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.
    &#34;&#34;&#34;
    wrapper_kwargs = wrapper_kwargs or {}
    env_kwargs = env_kwargs or {}
    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0
    seed = seed + 10000 * mpi_rank if seed is not None else None
    logger_dir = logger.get_dir()
    def make_thunk(rank, initializer=None):
        return lambda: make_env(
            env_id=env_id,
            env_type=env_type,
            mpi_rank=mpi_rank,
            subrank=rank,
            seed=seed,
            reward_scale=reward_scale,
            gamestate=gamestate,
            flatten_dict_observations=flatten_dict_observations,
            wrapper_kwargs=wrapper_kwargs,
            env_kwargs=env_kwargs,
            logger_dir=logger_dir,
            initializer=initializer
        )

    set_global_seeds(seed)
    if not force_dummy and num_env &gt; 1:
        return SubprocVecEnv([make_thunk(i + start_index, initializer=initializer) for i in range(num_env)])
    else:
        return DummyVecEnv([make_thunk(i + start_index, initializer=None) for i in range(num_env)])</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.mujoco_arg_parser"><code class="name flex">
<span>def <span class="ident">mujoco_arg_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mujoco_arg_parser():
    print(&#39;Obsolete - use common_arg_parser instead&#39;)
    return common_arg_parser()</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.parse_unknown_args"><code class="name flex">
<span>def <span class="ident">parse_unknown_args</span></span>(<span>args)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse arguments not consumed by arg parser into a dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_unknown_args(args):
    &#34;&#34;&#34;
    Parse arguments not consumed by arg parser into a dictionary
    &#34;&#34;&#34;
    retval = {}
    preceded_by_key = False
    for arg in args:
        if arg.startswith(&#39;--&#39;):
            if &#39;=&#39; in arg:
                key = arg.split(&#39;=&#39;)[0][2:]
                value = arg.split(&#39;=&#39;)[1]
                retval[key] = value
            else:
                key = arg[2:]
                preceded_by_key = True
        elif preceded_by_key:
            retval[key] = arg
            preceded_by_key = False

    return retval</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.openai_baselines.common.cmd_util.robotics_arg_parser"><code class="name flex">
<span>def <span class="ident">robotics_arg_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Create an argparse.ArgumentParser for run_mujoco.py.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def robotics_arg_parser():
    &#34;&#34;&#34;
    Create an argparse.ArgumentParser for run_mujoco.py.
    &#34;&#34;&#34;
    parser = arg_parser()
    parser.add_argument(&#39;--env&#39;, help=&#39;environment ID&#39;, type=str, default=&#39;FetchReach-v0&#39;)
    parser.add_argument(&#39;--seed&#39;, help=&#39;RNG seed&#39;, type=int, default=None)
    parser.add_argument(&#39;--num-timesteps&#39;, type=int, default=int(1e6))
    return parser</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">
<img src="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/home/head_image.png?raw=true" style="display: block; margin: 1em auto">
</a>
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">Home</a> | <a href="http://developmentalsystems.org/TeachMyAgent/">Website</a>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TeachMyAgent.students.openai_baselines.common" href="index.html">TeachMyAgent.students.openai_baselines.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.arg_parser" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.arg_parser">arg_parser</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.atari_arg_parser" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.atari_arg_parser">atari_arg_parser</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.common_arg_parser" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.common_arg_parser">common_arg_parser</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.make_env" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.make_env">make_env</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.make_mujoco_env" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.make_mujoco_env">make_mujoco_env</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.make_robotics_env" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.make_robotics_env">make_robotics_env</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.make_vec_env" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.make_vec_env">make_vec_env</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.mujoco_arg_parser" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.mujoco_arg_parser">mujoco_arg_parser</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.parse_unknown_args" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.parse_unknown_args">parse_unknown_args</a></code></li>
<li><code><a title="TeachMyAgent.students.openai_baselines.common.cmd_util.robotics_arg_parser" href="#TeachMyAgent.students.openai_baselines.common.cmd_util.robotics_arg_parser">robotics_arg_parser</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>